{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'texts_to_sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbighealth2.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Tokenize and pad the combined text (resume + job description)\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m sequences \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts_to_sequences\u001b[49m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     26\u001b[0m max_sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m  \u001b[38;5;66;03m# Use the same max length as before\u001b[39;00m\n\u001b[0;32m     27\u001b[0m data_padded \u001b[38;5;241m=\u001b[39m pad_sequences(sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_sequence_length)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'texts_to_sequences'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import os\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Disable GPU to avoid potential issues with LIME\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the preprocessed data\n",
    "data = pd.read_csv('dbhealthpreprocess.csv')\n",
    "\n",
    "# Load the tokenizer\n",
    "with open('tokenizershealth.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('bighealth2.keras')\n",
    "\n",
    "# Tokenize and pad the combined text (resume + job description)\n",
    "sequences = tokenizer.texts_to_sequences(data['combined_text'].values)\n",
    "max_sequence_length = 1500  # Use the same max length as before\n",
    "data_padded = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Tokenize and pad the nouns\n",
    "nouns_sequences = tokenizer.texts_to_sequences(data['nouns_str'].values)\n",
    "max_nouns_length = 10  # Use the same max length as before\n",
    "nouns_data = pad_sequences(nouns_sequences, maxlen=max_nouns_length)\n",
    "\n",
    "# Your target variable\n",
    "y = data['ATS_Score'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_padded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict([X_test, nouns_data[:len(X_test)]])\n",
    "\n",
    "# Evaluate the model performance with regression metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Custom prediction function for LIME that returns words instead of token indices\n",
    "def predict_proba(texts):\n",
    "    # Convert text into sequences\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "    \n",
    "    # Use the first example's nouns as input since LIME generally alters the text part, not the nouns.\n",
    "    nouns_input = np.tile(nouns_data[0], (len(texts), 1))  # Repeat the same nouns for all samples\n",
    "    \n",
    "    # Use the model to predict the ATS score\n",
    "    predictions = model.predict([padded, nouns_input])\n",
    "    \n",
    "    # Create a dummy probability for a second class (1 - prediction)\n",
    "    dummy_proba = 1 - predictions\n",
    "    \n",
    "    # Map sequences back to words for LIME interpretation\n",
    "    inverse_word_index = {v: k for k, v in tokenizer.word_index.items()}\n",
    "    words = [[inverse_word_index.get(idx, '') for idx in seq if idx != 0] for seq in sequences]\n",
    "    words_joined = [' '.join(word_list) for word_list in words]\n",
    "    \n",
    "    # Return a 2D array with probabilities for both classes\n",
    "    return np.column_stack((dummy_proba, predictions))\n",
    "\n",
    "# Instantiate the explainer with class names for better readability\n",
    "explainer = LimeTextExplainer(class_names=['negative', 'positive'])\n",
    "\n",
    "# Choose a single example from the test set to explain, limit the text size\n",
    "idx = 0  # Example index, you can change this to explain different instances\n",
    "text_instance = data['combined_text'].iloc[idx]\n",
    "\n",
    "# Generate the explanation with a reduced number of samples using the wrapper function\n",
    "exp = explainer.explain_instance(text_instance, predict_proba, num_features=10, num_samples=500)\n",
    "\n",
    "# Display the explanation\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 774ms/step\n",
      "Mean Absolute Error (MAE): 12.7844\n",
      "Root Mean Squared Error (RMSE): 15.4666\n",
      "R² Score: 0.1343\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import os\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Disable GPU to avoid potential issues with LIME\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the preprocessed data\n",
    "data = pd.read_csv('dbhealthpreprocess.csv')\n",
    "\n",
    "# Load the dictionary of tokenizers\n",
    "with open(r'tokenizershealth.pkl', 'rb') as handle:\n",
    "    tokenizers = pickle.load(handle)\n",
    "\n",
    "# Extract tokenizers from the dictionary\n",
    "resume_tokenizer = tokenizers['resume_tokenizer']\n",
    "description_tokenizer = tokenizers['description_tokenizer']\n",
    "common_nouns_tokenizer = tokenizers['common_nouns_tokenizer']\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('bighealth2.keras')\n",
    "\n",
    "\n",
    "max_sequence_length = 1500  # Use the same max length as before\n",
    "\n",
    "# Tokenize and pad the combined text (resume + job description)\n",
    "description_sequences = description_tokenizer.texts_to_sequences(data['processed_description'])\n",
    "description_data_padded = pad_sequences(description_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# sequences_desc = description_tokenizer.texts_to_sequences(data['description'].values)\n",
    "# data_padded = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "\n",
    "resume_sequences = resume_tokenizer.texts_to_sequences(data['processed_resume'])\n",
    "resume_data_padded = pad_sequences(resume_sequences, maxlen=max_sequence_length)\n",
    "# Tokenize and pad the combined text (resume + job description)\n",
    "# sequences_res = resume_tokenizer.texts_to_sequences(data['Resume_str'].values)\n",
    "# max_sequence_length = 1500  # Use the same max length as before\n",
    "# data_padded = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "\n",
    "# Tokenize and pad the nouns\n",
    "nouns_sequences = common_nouns_tokenizer.texts_to_sequences(data['common_nouns'].values)\n",
    "max_nouns_length = 10  # Use the same max length as before\n",
    "nouns_data = pad_sequences(nouns_sequences, maxlen=max_nouns_length)\n",
    "\n",
    "# Your target variable\n",
    "y = data['ATS_Score'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(resume_data_padded, description_data_padded, nouns_data, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict([resume_data_padded, description_data_padded, nouns_data])\n",
    "\n",
    "y_test = data['ATS_Score']\n",
    "\n",
    "# Evaluate the model performance with regression metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# ... your previous code ...\n",
    "\n",
    "# Reconstruct text from padded sequences\n",
    "def reconstruct_text(resume_seq, description_seq, nouns_seq):\n",
    "    resume_text = ' '.join(resume_tokenizer.sequences_to_texts([resume_seq])[0])\n",
    "    description_text = ' '.join(description_tokenizer.sequences_to_texts([description_seq])[0])\n",
    "    nouns_text = ' '.join(common_nouns_tokenizer.sequences_to_texts([nouns_seq])[0])\n",
    "    combined_text = resume_text + ' ' + description_text + ' ' + nouns_text\n",
    "    return combined_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create LIME explainer\n",
    "explainer = LimeTextExplainer(class_names=['ATS_Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explain a prediction\n",
    "index = 10  # Replace with the index of the instance you want to explain\n",
    "instance = reconstruct_text(resume_data_padded[index], description_data_padded[index], nouns_data[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(instance, model.predict, num_features=10)\n",
    "exp.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 582ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 45\u001b[0m\n\u001b[0;32m     39\u001b[0m combined_text_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_resume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[index_to_explain]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m     40\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[index_to_explain]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m     41\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommon_nouns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[index_to_explain]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Generate explanation\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_text_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Display the explanation in a readable format\u001b[39;00m\n\u001b[0;32m     48\u001b[0m exp\u001b[38;5;241m.\u001b[39mshow_in_notebook(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_text.py:429\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    425\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mtop_labels\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[0;32m    427\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[0;32m    428\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[1;32m--> 429\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore, ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance_with_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret_exp\n",
      "File \u001b[1;32mc:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_base.py:182\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[1;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    local_pred is the prediction of the explanation model on the original instance\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    181\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(distances)\n\u001b[1;32m--> 182\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m \u001b[43mneighborhood_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    183\u001b[0m used_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection(neighborhood_data,\n\u001b[0;32m    184\u001b[0m                                        labels_column,\n\u001b[0;32m    185\u001b[0m                                        weights,\n\u001b[0;32m    186\u001b[0m                                        num_features,\n\u001b[0;32m    187\u001b[0m                                        feature_selection)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "\n",
    "class ATSScorePredictor:\n",
    "    def __init__(self, model, resume_tokenizer, description_tokenizer, common_nouns_tokenizer, max_sequence_length, max_nouns_length):\n",
    "        self.model = model\n",
    "        self.resume_tokenizer = resume_tokenizer\n",
    "        self.description_tokenizer = description_tokenizer\n",
    "        self.common_nouns_tokenizer = common_nouns_tokenizer\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.max_nouns_length = max_nouns_length\n",
    "\n",
    "    def predict(self, texts):\n",
    "        # Split the input into resume, description, and nouns parts\n",
    "        resume_texts = [text[0] for text in texts]\n",
    "        description_texts = [text[1] for text in texts]\n",
    "        noun_texts = [text[2] for text in texts]\n",
    "\n",
    "        # Tokenize and pad each part\n",
    "        resume_sequences = self.resume_tokenizer.texts_to_sequences(resume_texts)\n",
    "        resume_data_padded = pad_sequences(resume_sequences, maxlen=self.max_sequence_length)\n",
    "\n",
    "        description_sequences = self.description_tokenizer.texts_to_sequences(description_texts)\n",
    "        description_data_padded = pad_sequences(description_sequences, maxlen=self.max_sequence_length)\n",
    "\n",
    "        nouns_sequences = self.common_nouns_tokenizer.texts_to_sequences(noun_texts)\n",
    "        nouns_data = pad_sequences(nouns_sequences, maxlen=self.max_nouns_length)\n",
    "\n",
    "        # Return the prediction as a flattened array\n",
    "        return self.model.predict([resume_data_padded, description_data_padded, nouns_data]).flatten()\n",
    "\n",
    "# Create an instance of the predictor\n",
    "predictor = ATSScorePredictor(model, resume_tokenizer, description_tokenizer, common_nouns_tokenizer, max_sequence_length, max_nouns_length)\n",
    "\n",
    "# Create an instance of LIME Text Explainer\n",
    "explainer = LimeTextExplainer(class_names=['ATS Score'])\n",
    "\n",
    "# Sample data point to explain (you can loop over multiple samples)\n",
    "index_to_explain = 0  # Choose an index to explain\n",
    "\n",
    "# Combine the resume, description, and nouns into a single list\n",
    "combined_text_instance = f\"{data['processed_resume'].iloc[index_to_explain]} \" \\\n",
    "                         f\"{data['processed_description'].iloc[index_to_explain]} \" \\\n",
    "                         f\"{data['common_nouns'].iloc[index_to_explain]}\"\n",
    "\n",
    "\n",
    "# Generate explanation\n",
    "exp = explainer.explain_instance(combined_text_instance, predictor.predict, num_features=10)\n",
    "\n",
    "# Display the explanation in a readable format\n",
    "exp.show_in_notebook(text=True)\n",
    "\n",
    "# Or to print the explanation\n",
    "print(exp.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 49\u001b[0m\n\u001b[0;32m     42\u001b[0m combined_text_instance \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     43\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_resume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[index_to_explain],\n\u001b[0;32m     44\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[index_to_explain],\n\u001b[0;32m     45\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommon_nouns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[index_to_explain]\n\u001b[0;32m     46\u001b[0m ]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Generate explanation\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_text_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Display the explanation in a readable format\u001b[39;00m\n\u001b[0;32m     52\u001b[0m exp\u001b[38;5;241m.\u001b[39mshow_in_notebook(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_text.py:409\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain_instance\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    369\u001b[0m                      text_instance,\n\u001b[0;32m    370\u001b[0m                      classifier_fn,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m                      distance_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    376\u001b[0m                      model_regressor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    377\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates explanations for a prediction.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m    First, we generate neighborhood data by randomly hiding features from\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m        explanations.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     indexed_string \u001b[38;5;241m=\u001b[39m (IndexedCharacters(\n\u001b[0;32m    407\u001b[0m         text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow, mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string)\n\u001b[0;32m    408\u001b[0m                       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_level \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m                       \u001b[43mIndexedString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msplit_expression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmask_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_string\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    412\u001b[0m     domain_mapper \u001b[38;5;241m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[0;32m    413\u001b[0m     data, yss, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data_labels_distances(\n\u001b[0;32m    414\u001b[0m         indexed_string, classifier_fn, num_samples,\n\u001b[0;32m    415\u001b[0m         distance_metric\u001b[38;5;241m=\u001b[39mdistance_metric)\n",
      "File \u001b[1;32mc:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_text.py:114\u001b[0m, in \u001b[0;36mIndexedString.__init__\u001b[1;34m(self, raw_string, split_expression, bow, mask_string)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# with the split_expression as a non-capturing group (?:), we don't need to filter out\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# the separator character from the split results.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     splitter \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)|$\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m split_expression)\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_list \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m splitter\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw) \u001b[38;5;28;01mif\u001b[39;00m s]\n\u001b[0;32m    115\u001b[0m     non_word \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39mmatch\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_list)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object, got 'list'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ATSScorePredictor:\n",
    "    def __init__(self, model, resume_tokenizer, description_tokenizer, common_nouns_tokenizer, max_sequence_length, max_nouns_length):\n",
    "        self.model = model\n",
    "        self.resume_tokenizer = resume_tokenizer\n",
    "        self.description_tokenizer = description_tokenizer\n",
    "        self.common_nouns_tokenizer = common_nouns_tokenizer\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.max_nouns_length = max_nouns_length\n",
    "\n",
    "    def predict(self, texts):\n",
    "        # Split the input into resume, description, and nouns parts\n",
    "        resume_texts = [text[0] for text in texts]\n",
    "        description_texts = [text[1] for text in texts]\n",
    "        noun_texts = [text[2] for text in texts]\n",
    "\n",
    "        # Tokenize and pad each part\n",
    "        resume_sequences = self.resume_tokenizer.texts_to_sequences(resume_texts)\n",
    "        resume_data_padded = pad_sequences(resume_sequences, maxlen=self.max_sequence_length)\n",
    "\n",
    "        description_sequences = self.description_tokenizer.texts_to_sequences(description_texts)\n",
    "        description_data_padded = pad_sequences(description_sequences, maxlen=self.max_sequence_length)\n",
    "\n",
    "        nouns_sequences = self.common_nouns_tokenizer.texts_to_sequences(noun_texts)\n",
    "        nouns_data = pad_sequences(nouns_sequences, maxlen=self.max_nouns_length)\n",
    "\n",
    "        # Get the predictions and return them as a 2D array\n",
    "        predictions = self.model.predict([resume_data_padded, description_data_padded, nouns_data])\n",
    "        return np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "# Create an instance of the predictor\n",
    "predictor = ATSScorePredictor(model, resume_tokenizer, description_tokenizer, common_nouns_tokenizer, max_sequence_length, max_nouns_length)\n",
    "\n",
    "# Create an instance of LIME Text Explainer\n",
    "explainer = LimeTextExplainer(class_names=['ATS Score'])\n",
    "\n",
    "# Sample data point to explain (you can loop over multiple samples)\n",
    "index_to_explain = 0  # Choose an index to explain\n",
    "\n",
    "# Combine the resume, description, and nouns into a single list\n",
    "combined_text_instance = [\n",
    "    data['processed_resume'].iloc[index_to_explain],\n",
    "    data['processed_description'].iloc[index_to_explain],\n",
    "    data['common_nouns'].iloc[index_to_explain]\n",
    "]\n",
    "\n",
    "# Generate explanation\n",
    "exp = explainer.explain_instance(combined_text_instance, predictor.predict, num_features=10)\n",
    "\n",
    "# Display the explanation in a readable format\n",
    "exp.show_in_notebook(text=True)\n",
    "\n",
    "# Or to print the explanation\n",
    "print(exp.as_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of LIME Text Explainer\n",
    "explainer = LimeTextExplainer(class_names=['ATS Score'])\n",
    "\n",
    "# Sample data point to explain (you can loop over multiple samples)\n",
    "index_to_explain = 0  # Choose an index to explain\n",
    "\n",
    "# Combine the resume, description, and nouns into a single string\n",
    "combined_text_instance = f\"{data['processed_resume'].iloc[index_to_explain]} \" \\\n",
    "                         f\"{data['processed_description'].iloc[index_to_explain]} \" \\\n",
    "                         f\"{data['common_nouns'].iloc[index_to_explain]}\"\n",
    "\n",
    "# Generate explanation\n",
    "exp = explainer.explain_instance(combined_text_instance, predictor.predict, num_features=10)\n",
    "\n",
    "# Display the explanation in a readable format\n",
    "exp.show_in_notebook(text=True)\n",
    "\n",
    "# Or to print the explanation\n",
    "print(exp.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictor\u001b[38;5;241m.\u001b[39mpredict(preprocessed_texts)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Generate explanation\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_text_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlime_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Display the explanation in a readable format\u001b[39;00m\n\u001b[0;32m     88\u001b[0m exp\u001b[38;5;241m.\u001b[39mshow_in_notebook(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_text.py:429\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    425\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mtop_labels\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[0;32m    427\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[0;32m    428\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[1;32m--> 429\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore, ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance_with_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret_exp\n",
      "File \u001b[1;32mc:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_base.py:182\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[1;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    local_pred is the prediction of the explanation model on the original instance\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    181\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(distances)\n\u001b[1;32m--> 182\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m \u001b[43mneighborhood_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    183\u001b[0m used_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection(neighborhood_data,\n\u001b[0;32m    184\u001b[0m                                        labels_column,\n\u001b[0;32m    185\u001b[0m                                        weights,\n\u001b[0;32m    186\u001b[0m                                        num_features,\n\u001b[0;32m    187\u001b[0m                                        feature_selection)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import os\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# Disable GPU to avoid potential issues with LIME\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the preprocessed data\n",
    "data = pd.read_csv('dbhealthpreprocess.csv')\n",
    "\n",
    "# Load the dictionary of tokenizers\n",
    "with open('tokenizershealth.pkl', 'rb') as handle:\n",
    "    tokenizers = pickle.load(handle)\n",
    "\n",
    "# Extract tokenizers from the dictionary\n",
    "resume_tokenizer = tokenizers['resume_tokenizer']\n",
    "description_tokenizer = tokenizers['description_tokenizer']\n",
    "common_nouns_tokenizer = tokenizers['common_nouns_tokenizer']\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('bighealth2.keras')\n",
    "\n",
    "# Set the maximum sequence lengths\n",
    "max_sequence_length = 1500  # For resume and description\n",
    "max_nouns_length = 10       # For common nouns\n",
    "\n",
    "# Define a class for predicting ATS scores\n",
    "class ATSScorePredictor:\n",
    "    def __init__(self, model, resume_tokenizer, description_tokenizer, common_nouns_tokenizer, max_sequence_length, max_nouns_length):\n",
    "        self.model = model\n",
    "        self.resume_tokenizer = resume_tokenizer\n",
    "        self.description_tokenizer = description_tokenizer\n",
    "        self.common_nouns_tokenizer = common_nouns_tokenizer\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.max_nouns_length = max_nouns_length\n",
    "\n",
    "    def predict(self, texts):\n",
    "        # Texts is a list where each element is a tuple of (resume_text, description_text, nouns_text)\n",
    "        resume_texts = [text[0] for text in texts]\n",
    "        description_texts = [text[1] for text in texts]\n",
    "        noun_texts = [text[2] for text in texts]\n",
    "\n",
    "        # Tokenize and pad each part\n",
    "        resume_sequences = self.resume_tokenizer.texts_to_sequences(resume_texts)\n",
    "        resume_data_padded = pad_sequences(resume_sequences, maxlen=self.max_sequence_length)\n",
    "\n",
    "        description_sequences = self.description_tokenizer.texts_to_sequences(description_texts)\n",
    "        description_data_padded = pad_sequences(description_sequences, maxlen=self.max_sequence_length)\n",
    "\n",
    "        nouns_sequences = self.common_nouns_tokenizer.texts_to_sequences(noun_texts)\n",
    "        nouns_data = pad_sequences(nouns_sequences, maxlen=self.max_nouns_length)\n",
    "\n",
    "        # Get the predictions and return them as a 2D array\n",
    "        predictions = self.model.predict([resume_data_padded, description_data_padded, nouns_data])\n",
    "        return np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "# Create an instance of the predictor\n",
    "predictor = ATSScorePredictor(model, resume_tokenizer, description_tokenizer, common_nouns_tokenizer, max_sequence_length, max_nouns_length)\n",
    "\n",
    "# Create an instance of LIME Text Explainer\n",
    "explainer = LimeTextExplainer()\n",
    "\n",
    "# Sample data point to explain\n",
    "index_to_explain = 0  # Choose an index to explain\n",
    "\n",
    "# Combine the resume, description, and nouns into a single string\n",
    "combined_text_instance = f\"{data['processed_resume'].iloc[index_to_explain]} \" \\\n",
    "                         f\"{data['processed_description'].iloc[index_to_explain]} \" \\\n",
    "                         f\"{data['common_nouns'].iloc[index_to_explain]}\"\n",
    "\n",
    "# Define a function to convert combined text into a format that LIME expects\n",
    "def preprocess_instance(instance):\n",
    "    return [instance]\n",
    "\n",
    "# Define a function for LIME to predict on combined text instances\n",
    "def lime_predict(texts):\n",
    "    preprocessed_texts = preprocess_instance(texts[0])\n",
    "    return predictor.predict(preprocessed_texts)\n",
    "\n",
    "# Generate explanation\n",
    "exp = explainer.explain_instance(combined_text_instance, lime_predict, num_features=10)\n",
    "\n",
    "# Display the explanation in a readable format\n",
    "exp.show_in_notebook(text=True)\n",
    "\n",
    "# Or to print the explanation in a list format\n",
    "print(exp.as_list())\n",
    "\n",
    "# Evaluate the model performance with regression metrics\n",
    "y_test = np.array([data['ATS_Score'].iloc[index_to_explain]])\n",
    "y_pred = predictor.predict([combined_text_instance])[0]\n",
    "\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "r2 = 1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictor\u001b[38;5;241m.\u001b[39mpredict(preprocessed_texts)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Generate explanation\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_text_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlime_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Display the explanation in a readable format\u001b[39;00m\n\u001b[0;32m     88\u001b[0m exp\u001b[38;5;241m.\u001b[39mshow_in_notebook(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_text.py:429\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    425\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mtop_labels\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[0;32m    427\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[0;32m    428\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[1;32m--> 429\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore, ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance_with_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret_exp\n",
      "File \u001b[1;32mc:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_base.py:182\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[1;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    local_pred is the prediction of the explanation model on the original instance\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    181\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(distances)\n\u001b[1;32m--> 182\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m \u001b[43mneighborhood_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    183\u001b[0m used_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection(neighborhood_data,\n\u001b[0;32m    184\u001b[0m                                        labels_column,\n\u001b[0;32m    185\u001b[0m                                        weights,\n\u001b[0;32m    186\u001b[0m                                        num_features,\n\u001b[0;32m    187\u001b[0m                                        feature_selection)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import os\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# Disable GPU to avoid potential issues with LIME\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the preprocessed data\n",
    "data = pd.read_csv('dbhealthpreprocess.csv')\n",
    "\n",
    "# Load the dictionary of tokenizers\n",
    "with open('tokenizershealth.pkl', 'rb') as handle:\n",
    "    tokenizers = pickle.load(handle)\n",
    "\n",
    "# Extract tokenizers from the dictionary\n",
    "resume_tokenizer = tokenizers['resume_tokenizer']\n",
    "description_tokenizer = tokenizers['description_tokenizer']\n",
    "common_nouns_tokenizer = tokenizers['common_nouns_tokenizer']\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('bighealth2.keras')\n",
    "\n",
    "# Set the maximum sequence lengths\n",
    "max_sequence_length = 1500  # For resume and description\n",
    "max_nouns_length = 10       # For common nouns\n",
    "\n",
    "# Define a class for predicting ATS scores\n",
    "class ATSScorePredictor:\n",
    "    def __init__(self, model, resume_tokenizer, description_tokenizer, common_nouns_tokenizer, max_sequence_length, max_nouns_length):\n",
    "        self.model = model\n",
    "        self.resume_tokenizer = resume_tokenizer\n",
    "        self.description_tokenizer = description_tokenizer\n",
    "        self.common_nouns_tokenizer = common_nouns_tokenizer\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.max_nouns_length = max_nouns_length\n",
    "\n",
    "    def predict(self, texts):\n",
    "        # Texts is a list where each element is a tuple of (resume_text, description_text, nouns_text)\n",
    "        resume_texts = [text[0] for text in texts]\n",
    "        description_texts = [text[1] for text in texts]\n",
    "        noun_texts = [text[2] for text in texts]\n",
    "\n",
    "        # Tokenize and pad each part\n",
    "        resume_sequences = self.resume_tokenizer.texts_to_sequences(resume_texts)\n",
    "        resume_data_padded = pad_sequences(resume_sequences, maxlen=self.max_sequence_length)\n",
    "\n",
    "        description_sequences = self.description_tokenizer.texts_to_sequences(description_texts)\n",
    "        description_data_padded = pad_sequences(description_sequences, maxlen=self.max_sequence_length)\n",
    "\n",
    "        nouns_sequences = self.common_nouns_tokenizer.texts_to_sequences(noun_texts)\n",
    "        nouns_data = pad_sequences(nouns_sequences, maxlen=self.max_nouns_length)\n",
    "\n",
    "        # Get the predictions and return them as a 2D array with shape (n_samples, 1)\n",
    "        predictions = self.model.predict([resume_data_padded, description_data_padded, nouns_data])\n",
    "        return predictions.reshape(-1, 1)  # Ensure predictions are shaped correctly\n",
    "\n",
    "# Create an instance of the predictor\n",
    "predictor = ATSScorePredictor(model, resume_tokenizer, description_tokenizer, common_nouns_tokenizer, max_sequence_length, max_nouns_length)\n",
    "\n",
    "# Create an instance of LIME Text Explainer\n",
    "explainer = LimeTextExplainer()\n",
    "\n",
    "# Sample data point to explain\n",
    "index_to_explain = 0  # Choose an index to explain\n",
    "\n",
    "# Combine the resume, description, and nouns into a single string\n",
    "combined_text_instance = f\"{data['processed_resume'].iloc[index_to_explain]} \" \\\n",
    "                         f\"{data['processed_description'].iloc[index_to_explain]} \" \\\n",
    "                         f\"{data['common_nouns'].iloc[index_to_explain]}\"\n",
    "\n",
    "# Define a function to convert combined text into a format that LIME expects\n",
    "def preprocess_instance(instance):\n",
    "    return [instance]\n",
    "\n",
    "# Define a function for LIME to predict on combined text instances\n",
    "def lime_predict(texts):\n",
    "    preprocessed_texts = preprocess_instance(texts[0])\n",
    "    return predictor.predict(preprocessed_texts)\n",
    "\n",
    "# Generate explanation\n",
    "exp = explainer.explain_instance(combined_text_instance, lime_predict, num_features=10)\n",
    "\n",
    "# Display the explanation in a readable format\n",
    "exp.show_in_notebook(text=True)\n",
    "\n",
    "# Or to print the explanation in a list format\n",
    "print(exp.as_list())\n",
    "\n",
    "# Evaluate the model performance with regression metrics\n",
    "y_test = np.array([data['ATS_Score'].iloc[index_to_explain]])\n",
    "y_pred = predictor.predict([combined_text_instance])[0]\n",
    "\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "r2 = 1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
